{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"MrTRIILya20P"},"outputs":[],"source":["import re\n","import csv\n","\n","import torch\n","import pandas as pd\n","from transformers import AutoTokenizer, AutoModelForCausalLM\n","from sklearn.metrics import accuracy_score\n","\n","# =============================================================================\n","# DATA LOADING\n","# =============================================================================\n","\n","def load_data(csv_file_path):\n","    \"\"\"Load data from CSV file into list of dicts.\"\"\"\n","    with open(csv_file_path, 'r', encoding='utf-8') as f:\n","        return list(csv.DictReader(f))\n","\n","def load_prompt_template(prompt_file):\n","    \"\"\"Load prompt template from file.\"\"\"\n","    with open(prompt_file, 'r', encoding='utf-8') as f:\n","        return f.read().strip()\n","\n","# =============================================================================\n","# MODEL MANAGEMENT\n","# =============================================================================\n","\n","def load_model(model_name):\n","    \"\"\"Load model and tokenizer.\"\"\"\n","    print(f\"Loading {model_name}...\")\n","    try:\n","        tokenizer = AutoTokenizer.from_pretrained(model_name)\n","        model = AutoModelForCausalLM.from_pretrained(\n","            model_name,\n","            torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n","            device_map=\"auto\" if torch.cuda.is_available() else None\n","        )\n","\n","        if tokenizer.pad_token is None:\n","            tokenizer.pad_token = tokenizer.eos_token\n","\n","        print(f\"✓ Loaded {model_name}\")\n","        return tokenizer, model\n","    except Exception as e:\n","        print(f\"✗ Failed to load {model_name}: {e}\")\n","        return None, None\n","\n","def cleanup_model():\n","    \"\"\"Clear GPU memory.\"\"\"\n","    if torch.cuda.is_available():\n","        torch.cuda.empty_cache()\n","\n","# =============================================================================\n","# PREDICTION\n","# =============================================================================\n","\n","def create_prompt(intervention, cq, template):\n","    \"\"\"Create prompt from template.\"\"\"\n","    return template.format(intervention=intervention, cq=cq)\n","\n","def generate_prediction(prompt, tokenizer, model):\n","    \"\"\"Generate model prediction.\"\"\"\n","    # Format with chat template\n","    if tokenizer.chat_template:\n","        messages = [{\"role\": \"user\", \"content\": prompt}]\n","        formatted_input = tokenizer.apply_chat_template(messages, tokenize=False)\n","    else:\n","        formatted_input = f\"<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant\\n\"\n","\n","    # Generate\n","    inputs = tokenizer(formatted_input, return_tensors=\"pt\")\n","    if torch.cuda.is_available():\n","        inputs = inputs.to(\"cuda\")\n","\n","    with torch.no_grad():\n","        outputs = model.generate(\n","            inputs.input_ids,\n","            max_new_tokens=100,\n","            temperature=0.7,\n","            top_p=0.9,\n","            do_sample=True,\n","            pad_token_id=tokenizer.pad_token_id\n","        )\n","\n","    # Decode response\n","    response = tokenizer.decode(outputs[0][inputs.input_ids.shape[1]:], skip_special_tokens=True)\n","    response = re.sub(r'<\\|assistant\\|>|</think>|header|system|user|assistant|subject', \"\", response)\n","    response = response.strip()\n","\n","    return classify_response(response)\n","\n","def classify_response(response):\n","    \"\"\"Classify response into Useful/Unhelpful/Invalid.\"\"\"\n","    response_lower = response.lower()\n","\n","    if 'useful' in response_lower:\n","        return 'Useful'\n","    elif 'unhelpful' in response_lower:\n","        return 'Unhelpful'\n","    elif 'invalid' in response_lower:\n","        return 'Invalid'\n","    else:\n","        return response  # Return raw response if no clear classification\n","\n","# =============================================================================\n","# EVALUATION\n","# =============================================================================\n","\n","def evaluate_single_item(item, tokenizer, model, template):\n","    \"\"\"Evaluate single CQ item.\"\"\"\n","    prompt = create_prompt(item['intervention'], item['cq'], template)\n","    prediction = generate_prediction(prompt, tokenizer, model)\n","\n","    return {\n","        'intervention_id': item['intervention_id'],\n","        'cq_id': item['cq_id'],\n","        'intervention': item['intervention'],\n","        'cq': item['cq'],\n","        'ground_truth': item['label'],\n","        'prediction': prediction\n","    }\n","\n","def run_evaluation(data_file, prompt_file, output_file='results.csv'):\n","    \"\"\"Run complete evaluation.\"\"\"\n","    # Load data and template\n","    data = load_data(data_file)\n","    template = load_prompt_template(prompt_file)\n","\n","    models = [\n","        \"Qwen/Qwen2.5-1.5B-Instruct\",\n","        \"Qwen/Qwen3-1.7B\",\n","        \"tiiuae/Falcon3-1B-Instruct\"\n","    ]\n","\n","    all_results = []\n","\n","    for model_name in models:\n","        print(f\"\\n{'='*50}\")\n","        print(f\"Evaluating with: {model_name}\")\n","        print(f\"{'='*50}\")\n","\n","        # Load model\n","        tokenizer, model = load_model(model_name)\n","        if tokenizer is None or model is None:\n","            continue\n","\n","        # Evaluate each item\n","        for i, item in enumerate(data):\n","            print(f\"Processing {i+1}/{len(data)}: {item['cq_id']}\")\n","\n","            result = evaluate_single_item(item, tokenizer, model, template)\n","            result['model'] = model_name\n","            all_results.append(result)\n","\n","            # Save progress every 10 items\n","            if (i + 1) % 10 == 0:\n","                save_results(all_results, output_file)\n","                print(f\"Progress saved at {i+1} items\")\n","\n","        # Cleanup\n","        del tokenizer, model\n","        cleanup_model()\n","        print(f\"Completed {model_name}\")\n","\n","    # Final save\n","    save_results(all_results, output_file)\n","    print(f\"\\nEvaluation complete. Results saved to {output_file}\")\n","    return all_results\n","\n","# =============================================================================\n","# RESULTS MANAGEMENT\n","# =============================================================================\n","\n","def save_results(results, filename):\n","    \"\"\"Save results to CSV.\"\"\"\n","    df = pd.DataFrame(results)\n","    df.to_csv(filename, index=False)\n","\n","def calculate_accuracy(results_file='results.csv'):\n","    \"\"\"Calculate accuracy for each model.\"\"\"\n","    df = pd.read_csv(results_file)\n","\n","    print(f\"\\nAccuracy Results:\")\n","    print(\"-\" * 40)\n","\n","    for model in df['model'].unique():\n","        model_data = df[df['model'] == model]\n","        accuracy = accuracy_score(model_data['ground_truth'], model_data['prediction'])\n","        print(f\"{model}: {accuracy:.4f}\")\n","\n","    return df\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["f02032a4f43a4dabab90107a96c16a14","34897a436809423dafba66220c6011b3","ff6a5ba9105c4102a44922acfc8c068c","48b8d5946c9a4c4f830ab03bc3537c8d","d5c768ab157e4d6eb2b735c326e065af","62b9acf536264e18b11b7a4bb9c6d365","a73329c051d94808a019345d1eab2838","995308d1825e486a823dccddad9852a7","fb1abc5f506148a6a32658a752378e76","e30e5873acc64ca3837825291aa0c38d","32c95c86449e4e1c82dc2d30dedb61ef"]},"id":"CkUGXBbaSq2d","outputId":"fe8d09b3-54a1-4d1f-d44c-86b97c0a43a9"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","==================================================\n","Evaluating with: Qwen/Qwen2.5-1.5B-Instruct\n","==================================================\n","Loading Qwen/Qwen2.5-1.5B-Instruct...\n","✓ Loaded Qwen/Qwen2.5-1.5B-Instruct\n","Processing 1/100: secretcurse__137_LLM_us2016reddit_D_meta-llama_Meta-Llama-3-70B-Instruct_5_S\n","Processing 2/100: JL_3_LLM_moral_maze_schemes_D_meta-llama_Meta-Llama-3-70B-Instruct_7_L\n","Processing 3/100: CLINTON_225_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_5_L\n","Processing 4/100: MT_14_LLM_moral_maze_schemes_D_meta-llama_Meta-Llama-3-70B-Instruct_3_S\n","Processing 5/100: TRUMP_140_1_T__3\n","Processing 6/100: PeanutAllergy_232_T__0\n","Processing 7/100: TRUMP_240_2_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_2_S\n","Processing 8/100: CLINTON_244_2_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_6_S\n","Processing 9/100: howie_238_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_0_L\n","Processing 10/100: Javier_84_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_4_L\n","Progress saved at 10 items\n","Processing 11/100: TRUMP_9_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_1_S\n","Processing 12/100: CLINTON_199_1_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_5_L\n","Processing 13/100: CLINTON_1_2_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_7_S\n","Processing 14/100: 17th_knight__247_LLM_us2016reddit_D_meta-llama_Meta-Llama-3-70B-Instruct_0_S\n","Processing 15/100: JL_5_LLM_moral_maze_schemes_D_meta-llama_Meta-Llama-3-70B-Instruct_2_S\n","Processing 16/100: FoodAllergyMom_199_1_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_6_S\n","Processing 17/100: TRUMP_174_2_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_2_L\n","Processing 18/100: TRUMP_253_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_6_L\n","Processing 19/100: NYCMuscleman18_187_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_6_L\n","Processing 20/100: TRUMP_13_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_7_L\n","Progress saved at 20 items\n","Processing 21/100: TRUMP_26_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_1_L\n","Processing 22/100: Zewstain__641_LLM_us2016reddit_D_meta-llama_Meta-Llama-3-70B-Instruct_2_S\n","Processing 23/100: CLINTON_176_2_T__7\n","Processing 24/100: travellots_133_2_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_4_L\n","Processing 25/100: CLINTON_92_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_2_S\n","Processing 26/100: CLINTON_103_T__1\n","Processing 27/100: darawayne_182_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_0_L\n","Processing 28/100: TRUMP_26_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_5_L\n","Processing 29/100: smg_72_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_3_S\n","Processing 30/100: secretcurse__137_LLM_us2016reddit_D_meta-llama_Meta-Llama-3-70B-Instruct_6_S\n","Progress saved at 30 items\n","Processing 31/100: FoodAllergyMom_199_1_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_7_S\n","Processing 32/100: HOLT_126_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_5_L\n","Processing 33/100: TRUMP_77_1_T__7\n","Processing 34/100: Zewstain__641_LLM_us2016reddit_D_meta-llama_Meta-Llama-3-70B-Instruct_1_L\n","Processing 35/100: PeanutAllergy_232_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_3_S\n","Processing 36/100: travellots_133_1_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_7_S\n","Processing 37/100: TRUMP_279_T__2\n","Processing 38/100: TRUMP_93_T__0\n","Processing 39/100: Doctor-Mom_205_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_7_S\n","Processing 40/100: CLINTON_39_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_4_S\n","Progress saved at 40 items\n","Processing 41/100: CLINTON_123_1_T__11\n","Processing 42/100: TRUMP_101_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_0_L\n","Processing 43/100: TRUMP_114_1_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_9_L\n","Processing 44/100: Frequent-Flyer_157_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_3_L\n","Processing 45/100: mcliverty_188_1_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_3_L\n","Processing 46/100: TRUMP_192_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_3_S\n","Processing 47/100: Antanagoge_104_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_3_S\n","Processing 48/100: TRUMP_99_T__8\n","Processing 49/100: JL_15_LLM_moral_maze_schemes_D_meta-llama_Meta-Llama-3-70B-Instruct_7_S\n","Processing 50/100: JW_35_LLM_moral_maze_schemes_D_meta-llama_Meta-Llama-3-70B-Instruct_4_L\n","Progress saved at 50 items\n","Processing 51/100: TRUMP_236_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_0_S\n","Processing 52/100: CLINTON_123_2_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_5_L\n","Processing 53/100: TRUMP_253_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_1_L\n","Processing 54/100: CLINTON_130_2_T__2\n","Processing 55/100: TRUMP_77_1_T__17\n","Processing 56/100: CLINTON_6_2_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_5_L\n","Processing 57/100: TRUMP_121_2_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_2_L\n","Processing 58/100: smg_72_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_5_S\n","Processing 59/100: TRUMP_183_T__8\n","Processing 60/100: HOLT_126_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_6_L\n","Progress saved at 60 items\n","Processing 61/100: CLINTON_103_T__3\n","Processing 62/100: JJMurray_140_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_1_L\n","Processing 63/100: PeanutAllergy_232_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_2_L\n","Processing 64/100: CLINTON_231_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_6_L\n","Processing 65/100: TRUMP_13_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_6_S\n","Processing 66/100: CLINTON_235_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_1_S\n","Processing 67/100: Bill_106_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_6_S\n","Processing 68/100: TRUMP_125_2_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_1_S\n","Processing 69/100: TRUMP_114_2_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_1_S\n","Processing 70/100: TRUMP_3_1_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_1_L\n","Progress saved at 70 items\n","Processing 71/100: smg_72_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_8_S\n","Processing 72/100: TRUMP_125_2_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_0_L\n","Processing 73/100: CLINTON_37_T__8\n","Processing 74/100: TRUMP_121_2_T__9\n","Processing 75/100: TRUMP_202_1_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_4_S\n","Processing 76/100: Tuatho__98_LLM_us2016reddit_D_meta-llama_Meta-Llama-3-70B-Instruct_1_L\n","Processing 77/100: mcliverty_188_2_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_2_S\n","Processing 78/100: TRUMP_251_T__11\n","Processing 79/100: ND_23_LLM_moral_maze_schemes_D_meta-llama_Meta-Llama-3-70B-Instruct_1_L\n","Processing 80/100: CLINTON_130_1_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_0_S\n","Progress saved at 80 items\n","Processing 81/100: TRUMP_3_1_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_4_L\n","Processing 82/100: JDwyer_17_T__0\n","Processing 83/100: howie_213_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_2_L\n","Processing 84/100: CLINTON_186_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_9_S\n","Processing 85/100: Doctor-Mom_205_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_9_S\n","Processing 86/100: KHenrickson_172_T__0\n","Processing 87/100: Vec_164_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_6_L\n","Processing 88/100: golff4fun_162_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_6_S\n","Processing 89/100: TRUMP_279_T__10\n","Processing 90/100: CLINTON_176_2_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_7_S\n","Progress saved at 90 items\n","Processing 91/100: TRUMP_95_T__0\n","Processing 92/100: SofieM_128_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_1_S\n","Processing 93/100: TRUMP_112_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_2_S\n","Processing 94/100: TRUMP_93_T__14\n","Processing 95/100: CLINTON_92_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_7_L\n","Processing 96/100: MP_22_T__3\n","Processing 97/100: TRUMP_3_2_T__15\n","Processing 98/100: TRUMP_93_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_8_S\n","Processing 99/100: HOLT_126_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_3_S\n","Processing 100/100: CL_8_LLM_moral_maze_schemes_D_meta-llama_Meta-Llama-3-70B-Instruct_2_S\n","Progress saved at 100 items\n","Completed Qwen/Qwen2.5-1.5B-Instruct\n","\n","==================================================\n","Evaluating with: Qwen/Qwen3-1.7B\n","==================================================\n","Loading Qwen/Qwen3-1.7B...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f02032a4f43a4dabab90107a96c16a14","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["✓ Loaded Qwen/Qwen3-1.7B\n","Processing 1/100: secretcurse__137_LLM_us2016reddit_D_meta-llama_Meta-Llama-3-70B-Instruct_5_S\n","Processing 2/100: JL_3_LLM_moral_maze_schemes_D_meta-llama_Meta-Llama-3-70B-Instruct_7_L\n","Processing 3/100: CLINTON_225_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_5_L\n","Processing 4/100: MT_14_LLM_moral_maze_schemes_D_meta-llama_Meta-Llama-3-70B-Instruct_3_S\n","Processing 5/100: TRUMP_140_1_T__3\n","Processing 6/100: PeanutAllergy_232_T__0\n","Processing 7/100: TRUMP_240_2_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_2_S\n","Processing 8/100: CLINTON_244_2_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_6_S\n","Processing 9/100: howie_238_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_0_L\n","Processing 10/100: Javier_84_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_4_L\n","Progress saved at 10 items\n","Processing 11/100: TRUMP_9_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_1_S\n","Processing 12/100: CLINTON_199_1_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_5_L\n","Processing 13/100: CLINTON_1_2_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_7_S\n","Processing 14/100: 17th_knight__247_LLM_us2016reddit_D_meta-llama_Meta-Llama-3-70B-Instruct_0_S\n","Processing 15/100: JL_5_LLM_moral_maze_schemes_D_meta-llama_Meta-Llama-3-70B-Instruct_2_S\n","Processing 16/100: FoodAllergyMom_199_1_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_6_S\n","Processing 17/100: TRUMP_174_2_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_2_L\n","Processing 18/100: TRUMP_253_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_6_L\n","Processing 19/100: NYCMuscleman18_187_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_6_L\n","Processing 20/100: TRUMP_13_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_7_L\n","Progress saved at 20 items\n","Processing 21/100: TRUMP_26_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_1_L\n","Processing 22/100: Zewstain__641_LLM_us2016reddit_D_meta-llama_Meta-Llama-3-70B-Instruct_2_S\n","Processing 23/100: CLINTON_176_2_T__7\n","Processing 24/100: travellots_133_2_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_4_L\n","Processing 25/100: CLINTON_92_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_2_S\n","Processing 26/100: CLINTON_103_T__1\n","Processing 27/100: darawayne_182_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_0_L\n","Processing 28/100: TRUMP_26_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_5_L\n","Processing 29/100: smg_72_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_3_S\n","Processing 30/100: secretcurse__137_LLM_us2016reddit_D_meta-llama_Meta-Llama-3-70B-Instruct_6_S\n","Progress saved at 30 items\n","Processing 31/100: FoodAllergyMom_199_1_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_7_S\n","Processing 32/100: HOLT_126_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_5_L\n","Processing 33/100: TRUMP_77_1_T__7\n","Processing 34/100: Zewstain__641_LLM_us2016reddit_D_meta-llama_Meta-Llama-3-70B-Instruct_1_L\n","Processing 35/100: PeanutAllergy_232_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_3_S\n","Processing 36/100: travellots_133_1_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_7_S\n","Processing 37/100: TRUMP_279_T__2\n","Processing 38/100: TRUMP_93_T__0\n","Processing 39/100: Doctor-Mom_205_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_7_S\n","Processing 40/100: CLINTON_39_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_4_S\n","Progress saved at 40 items\n","Processing 41/100: CLINTON_123_1_T__11\n","Processing 42/100: TRUMP_101_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_0_L\n","Processing 43/100: TRUMP_114_1_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_9_L\n","Processing 44/100: Frequent-Flyer_157_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_3_L\n","Processing 45/100: mcliverty_188_1_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_3_L\n","Processing 46/100: TRUMP_192_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_3_S\n","Processing 47/100: Antanagoge_104_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_3_S\n","Processing 48/100: TRUMP_99_T__8\n","Processing 49/100: JL_15_LLM_moral_maze_schemes_D_meta-llama_Meta-Llama-3-70B-Instruct_7_S\n","Processing 50/100: JW_35_LLM_moral_maze_schemes_D_meta-llama_Meta-Llama-3-70B-Instruct_4_L\n","Progress saved at 50 items\n","Processing 51/100: TRUMP_236_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_0_S\n","Processing 52/100: CLINTON_123_2_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_5_L\n","Processing 53/100: TRUMP_253_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_1_L\n","Processing 54/100: CLINTON_130_2_T__2\n","Processing 55/100: TRUMP_77_1_T__17\n","Processing 56/100: CLINTON_6_2_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_5_L\n","Processing 57/100: TRUMP_121_2_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_2_L\n","Processing 58/100: smg_72_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_5_S\n","Processing 59/100: TRUMP_183_T__8\n","Processing 60/100: HOLT_126_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_6_L\n","Progress saved at 60 items\n","Processing 61/100: CLINTON_103_T__3\n","Processing 62/100: JJMurray_140_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_1_L\n","Processing 63/100: PeanutAllergy_232_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_2_L\n","Processing 64/100: CLINTON_231_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_6_L\n","Processing 65/100: TRUMP_13_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_6_S\n","Processing 66/100: CLINTON_235_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_1_S\n","Processing 67/100: Bill_106_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_6_S\n","Processing 68/100: TRUMP_125_2_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_1_S\n","Processing 69/100: TRUMP_114_2_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_1_S\n","Processing 70/100: TRUMP_3_1_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_1_L\n","Progress saved at 70 items\n","Processing 71/100: smg_72_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_8_S\n","Processing 72/100: TRUMP_125_2_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_0_L\n","Processing 73/100: CLINTON_37_T__8\n","Processing 74/100: TRUMP_121_2_T__9\n","Processing 75/100: TRUMP_202_1_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_4_S\n","Processing 76/100: Tuatho__98_LLM_us2016reddit_D_meta-llama_Meta-Llama-3-70B-Instruct_1_L\n","Processing 77/100: mcliverty_188_2_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_2_S\n","Processing 78/100: TRUMP_251_T__11\n","Processing 79/100: ND_23_LLM_moral_maze_schemes_D_meta-llama_Meta-Llama-3-70B-Instruct_1_L\n","Processing 80/100: CLINTON_130_1_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_0_S\n","Progress saved at 80 items\n","Processing 81/100: TRUMP_3_1_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_4_L\n","Processing 82/100: JDwyer_17_T__0\n","Processing 83/100: howie_213_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_2_L\n","Processing 84/100: CLINTON_186_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_9_S\n","Processing 85/100: Doctor-Mom_205_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_9_S\n","Processing 86/100: KHenrickson_172_T__0\n","Processing 87/100: Vec_164_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_6_L\n","Processing 88/100: golff4fun_162_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_6_S\n","Processing 89/100: TRUMP_279_T__10\n","Processing 90/100: CLINTON_176_2_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_7_S\n","Progress saved at 90 items\n","Processing 91/100: TRUMP_95_T__0\n","Processing 92/100: SofieM_128_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_1_S\n","Processing 93/100: TRUMP_112_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_2_S\n","Processing 94/100: TRUMP_93_T__14\n","Processing 95/100: CLINTON_92_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_7_L\n","Processing 96/100: MP_22_T__3\n","Processing 97/100: TRUMP_3_2_T__15\n","Processing 98/100: TRUMP_93_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_8_S\n","Processing 99/100: HOLT_126_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_3_S\n","Processing 100/100: CL_8_LLM_moral_maze_schemes_D_meta-llama_Meta-Llama-3-70B-Instruct_2_S\n","Progress saved at 100 items\n","Completed Qwen/Qwen3-1.7B\n","\n","==================================================\n","Evaluating with: tiiuae/Falcon3-1B-Instruct\n","==================================================\n","Loading tiiuae/Falcon3-1B-Instruct...\n","✓ Loaded tiiuae/Falcon3-1B-Instruct\n","Processing 1/100: secretcurse__137_LLM_us2016reddit_D_meta-llama_Meta-Llama-3-70B-Instruct_5_S\n","Processing 2/100: JL_3_LLM_moral_maze_schemes_D_meta-llama_Meta-Llama-3-70B-Instruct_7_L\n","Processing 3/100: CLINTON_225_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_5_L\n","Processing 4/100: MT_14_LLM_moral_maze_schemes_D_meta-llama_Meta-Llama-3-70B-Instruct_3_S\n","Processing 5/100: TRUMP_140_1_T__3\n","Processing 6/100: PeanutAllergy_232_T__0\n","Processing 7/100: TRUMP_240_2_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_2_S\n","Processing 8/100: CLINTON_244_2_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_6_S\n","Processing 9/100: howie_238_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_0_L\n","Processing 10/100: Javier_84_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_4_L\n","Progress saved at 10 items\n","Processing 11/100: TRUMP_9_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_1_S\n","Processing 12/100: CLINTON_199_1_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_5_L\n","Processing 13/100: CLINTON_1_2_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_7_S\n","Processing 14/100: 17th_knight__247_LLM_us2016reddit_D_meta-llama_Meta-Llama-3-70B-Instruct_0_S\n","Processing 15/100: JL_5_LLM_moral_maze_schemes_D_meta-llama_Meta-Llama-3-70B-Instruct_2_S\n","Processing 16/100: FoodAllergyMom_199_1_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_6_S\n","Processing 17/100: TRUMP_174_2_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_2_L\n","Processing 18/100: TRUMP_253_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_6_L\n","Processing 19/100: NYCMuscleman18_187_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_6_L\n","Processing 20/100: TRUMP_13_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_7_L\n","Progress saved at 20 items\n","Processing 21/100: TRUMP_26_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_1_L\n","Processing 22/100: Zewstain__641_LLM_us2016reddit_D_meta-llama_Meta-Llama-3-70B-Instruct_2_S\n","Processing 23/100: CLINTON_176_2_T__7\n","Processing 24/100: travellots_133_2_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_4_L\n","Processing 25/100: CLINTON_92_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_2_S\n","Processing 26/100: CLINTON_103_T__1\n","Processing 27/100: darawayne_182_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_0_L\n","Processing 28/100: TRUMP_26_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_5_L\n","Processing 29/100: smg_72_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_3_S\n","Processing 30/100: secretcurse__137_LLM_us2016reddit_D_meta-llama_Meta-Llama-3-70B-Instruct_6_S\n","Progress saved at 30 items\n","Processing 31/100: FoodAllergyMom_199_1_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_7_S\n","Processing 32/100: HOLT_126_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_5_L\n","Processing 33/100: TRUMP_77_1_T__7\n","Processing 34/100: Zewstain__641_LLM_us2016reddit_D_meta-llama_Meta-Llama-3-70B-Instruct_1_L\n","Processing 35/100: PeanutAllergy_232_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_3_S\n","Processing 36/100: travellots_133_1_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_7_S\n","Processing 37/100: TRUMP_279_T__2\n","Processing 38/100: TRUMP_93_T__0\n","Processing 39/100: Doctor-Mom_205_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_7_S\n","Processing 40/100: CLINTON_39_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_4_S\n","Progress saved at 40 items\n","Processing 41/100: CLINTON_123_1_T__11\n","Processing 42/100: TRUMP_101_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_0_L\n","Processing 43/100: TRUMP_114_1_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_9_L\n","Processing 44/100: Frequent-Flyer_157_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_3_L\n","Processing 45/100: mcliverty_188_1_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_3_L\n","Processing 46/100: TRUMP_192_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_3_S\n","Processing 47/100: Antanagoge_104_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_3_S\n","Processing 48/100: TRUMP_99_T__8\n","Processing 49/100: JL_15_LLM_moral_maze_schemes_D_meta-llama_Meta-Llama-3-70B-Instruct_7_S\n","Processing 50/100: JW_35_LLM_moral_maze_schemes_D_meta-llama_Meta-Llama-3-70B-Instruct_4_L\n","Progress saved at 50 items\n","Processing 51/100: TRUMP_236_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_0_S\n","Processing 52/100: CLINTON_123_2_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_5_L\n","Processing 53/100: TRUMP_253_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_1_L\n","Processing 54/100: CLINTON_130_2_T__2\n","Processing 55/100: TRUMP_77_1_T__17\n","Processing 56/100: CLINTON_6_2_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_5_L\n","Processing 57/100: TRUMP_121_2_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_2_L\n","Processing 58/100: smg_72_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_5_S\n","Processing 59/100: TRUMP_183_T__8\n","Processing 60/100: HOLT_126_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_6_L\n","Progress saved at 60 items\n","Processing 61/100: CLINTON_103_T__3\n","Processing 62/100: JJMurray_140_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_1_L\n","Processing 63/100: PeanutAllergy_232_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_2_L\n","Processing 64/100: CLINTON_231_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_6_L\n","Processing 65/100: TRUMP_13_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_6_S\n","Processing 66/100: CLINTON_235_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_1_S\n","Processing 67/100: Bill_106_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_6_S\n","Processing 68/100: TRUMP_125_2_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_1_S\n","Processing 69/100: TRUMP_114_2_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_1_S\n","Processing 70/100: TRUMP_3_1_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_1_L\n","Progress saved at 70 items\n","Processing 71/100: smg_72_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_8_S\n","Processing 72/100: TRUMP_125_2_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_0_L\n","Processing 73/100: CLINTON_37_T__8\n","Processing 74/100: TRUMP_121_2_T__9\n","Processing 75/100: TRUMP_202_1_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_4_S\n","Processing 76/100: Tuatho__98_LLM_us2016reddit_D_meta-llama_Meta-Llama-3-70B-Instruct_1_L\n","Processing 77/100: mcliverty_188_2_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_2_S\n","Processing 78/100: TRUMP_251_T__11\n","Processing 79/100: ND_23_LLM_moral_maze_schemes_D_meta-llama_Meta-Llama-3-70B-Instruct_1_L\n","Processing 80/100: CLINTON_130_1_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_0_S\n","Progress saved at 80 items\n","Processing 81/100: TRUMP_3_1_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_4_L\n","Processing 82/100: JDwyer_17_T__0\n","Processing 83/100: howie_213_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_2_L\n","Processing 84/100: CLINTON_186_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_9_S\n","Processing 85/100: Doctor-Mom_205_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_9_S\n","Processing 86/100: KHenrickson_172_T__0\n","Processing 87/100: Vec_164_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_6_L\n","Processing 88/100: golff4fun_162_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_6_S\n","Processing 89/100: TRUMP_279_T__10\n","Processing 90/100: CLINTON_176_2_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_7_S\n","Progress saved at 90 items\n","Processing 91/100: TRUMP_95_T__0\n","Processing 92/100: SofieM_128_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-Instruct_1_S\n","Processing 93/100: TRUMP_112_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_2_S\n","Processing 94/100: TRUMP_93_T__14\n","Processing 95/100: CLINTON_92_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_7_L\n","Processing 96/100: MP_22_T__3\n","Processing 97/100: TRUMP_3_2_T__15\n","Processing 98/100: TRUMP_93_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_8_S\n","Processing 99/100: HOLT_126_LLM_US2016_D_meta-llama_Meta-Llama-3-70B-Instruct_3_S\n","Processing 100/100: CL_8_LLM_moral_maze_schemes_D_meta-llama_Meta-Llama-3-70B-Instruct_2_S\n","Progress saved at 100 items\n","Completed tiiuae/Falcon3-1B-Instruct\n","\n","Evaluation complete. Results saved to results.csv\n","\n","Accuracy Results:\n","----------------------------------------\n","Qwen/Qwen2.5-1.5B-Instruct: 0.5300\n","Qwen/Qwen3-1.7B: 0.2300\n","tiiuae/Falcon3-1B-Instruct: 0.4800\n","Execution time: 601.81 seconds\n"]}],"source":["import time\n","\n","start_time = time.time()\n","results = run_evaluation('/content/extracted_intervention_cq_pairs.csv', '/content/scheme_classic_prompt.txt', 'results.csv')\n","accuracy_df = calculate_accuracy('results.csv')\n","end_time = time.time()\n","\n","execution_time = end_time - start_time\n","print(f\"Execution time: {execution_time:.2f} seconds\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":53,"status":"ok","timestamp":1749679166380,"user":{"displayName":"Liz Ershova","userId":"11160557817704427315"},"user_tz":-120},"id":"QO0I83YlSw-4","outputId":"13a86933-27ba-43f8-aa7c-3051cdfc57a8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Reformatted results saved to results_wide.csv\n"]}],"source":["import pandas as pd\n","\n","def reformat_results(input_file, output_file='results_wide.csv'):\n","    \"\"\"Convert long format to wide format with model predictions as columns.\"\"\"\n","    df = pd.read_csv(input_file)\n","\n","    # Pivot: keep base columns, spread model predictions across columns\n","    wide_df = df.pivot_table(\n","        index=['intervention_id', 'cq_id', 'intervention', 'cq', 'ground_truth'],\n","        columns='model',\n","        values='prediction',\n","        aggfunc='first'\n","    ).reset_index()\n","\n","    # Flatten column names\n","    wide_df.columns.name = None\n","\n","    wide_df.to_csv(output_file, index=False)\n","    print(f\"Reformatted results saved to {output_file}\")\n","    return wide_df\n","\n","reformatted = reformat_results('results.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xyToz5yEWsJY"},"outputs":[],"source":["from collections import Counter\n","def add_majority_vote(input_file, output_file='results_with_majority.csv'):\n","    \"\"\"Add majority vote column to wide format CSV file.\"\"\"\n","    wide_df = pd.read_csv(input_file)\n","\n","    # Get model columns (exclude base info columns)\n","    base_cols = ['intervention_id', 'cq_id', 'intervention', 'cq', 'ground_truth']\n","    model_cols = [col for col in wide_df.columns if col not in base_cols]\n","\n","    # Calculate majority vote for each row\n","    majority_votes = []\n","    for _, row in wide_df.iterrows():\n","        predictions = [row[col] for col in model_cols if pd.notna(row[col])]\n","        if predictions:\n","            vote_counts = Counter(predictions)\n","            majority_vote = vote_counts.most_common(1)[0][0]\n","        else:\n","            majority_vote = None\n","        majority_votes.append(majority_vote)\n","\n","    # Add majority vote column\n","    wide_df['majority_vote'] = majority_votes\n","\n","    wide_df.to_csv(output_file, index=False)\n","    print(f\"Results with majority vote saved to {output_file}\")\n","    return wide_df"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":78,"status":"ok","timestamp":1749679169998,"user":{"displayName":"Liz Ershova","userId":"11160557817704427315"},"user_tz":-120},"id":"KsG2i46lWziL","outputId":"2ba83b7b-2938-4628-9ec3-79af61e9a0a3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Results with majority vote saved to results_with_majority.csv\n"]},{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"summary":"{\n  \"name\": \"add_majority_vote(\\\"/content/results_wide\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"intervention_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 77,\n        \"samples\": [\n          \"CLINTON_123_1\",\n          \"ND_23\",\n          \"CLINTON_199_1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cq_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"Tuatho__98_LLM_us2016reddit_D_meta-llama_Meta-Llama-3-70B-Instruct_1_L\",\n          \"TRUMP_121_2_T__9\",\n          \"TRUMP_279_T__10\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"intervention\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 77,\n        \"samples\": [\n          \"CLINTON: \\\"Race remains a significant challenge in our country\\nUnfortunately, race still determines too much\\noften determines where people live\\ndetermines what kind of education in their public schools they can get,\\nit determines how they're treated in the criminal justice system\\nWe've just seen those two tragic examples in both Tulsa and Charlotte\\nwe've got to do several things at the same time\\nWe have to restore trust between communities and the police\\nWe have to work to make sure that our police are using the best training, the best techniques, that they're well prepared to use force only when necessary\\nEveryone should be respected by the law, and everyone should respect the law\\nRight now, that's not the case in a lot of our neighborhoods\\nI have, ever since the first day of my campaign, called for criminal justice reform\\\"\",\n          \"ND: \\\"\\u00a0I think in the current situation that both savers and borrowers, if you're talking about individual people, are doing extremely badly\\nmany people are unable to make ends meet and are having to take debt out at huge levels of interest\\nOn the other hand, savers are earning nothing in interest\\nAnd what this needs is not simply us putting moral blame on one side or the other\\nbut actually putting moral blame on a set of economic policies and political decisions that have led to credit liberalisation.\\\"\",\n          \"CLINTON: \\\"That's the most important part of this\\nHow do we prevent attacks\\nHow do we protect our people\\nwe've got to have an intelligence surge, where we are looking for every scrap of information\\nI was so proud of law enforcement in New York, in Minnesota, in New Jersey\\n they responded so quickly, so professionally to the attacks that occurred by Rahami\\nthey brought him down\\nwe may find out more information\\n he is still alive\\\"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cq\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"Is it not possible for someone to consider multiple factors, including a speaker's smoothness, when forming their political opinion?\",\n          \"Could Trump taking advantage of the laws of the nation have consequences that we should take into account? Is it practically possible?\",\n          \"Does not being corrupted imply deporting the people that had to be deported?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ground_truth\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Useful\",\n          \"Unhelpful\",\n          \"Invalid\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Qwen/Qwen2.5-1.5B-Instruct\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"Valid Critical Question: How does the concept of \\\"bumping\\\" differ from simply changing the flight schedule? And why might this distinction matter in evaluating the fairness of compensating passengers based on inconvenience caused by scheduling changes?\\n\\n**Final Answer:** Useless\",\n          \"Unhelpful\",\n          \"**Validated Critical Question:**\\n\\n**How does Trump's decision to settle a lawsuit without admitting guilt impact his stance on discrimination issues?**\\n\\nThis question effectively challenges the statement about discrimination by exploring the implications of not admitting guilt in legal disputes. It prompts consideration of how such decisions might reflect broader attitudes towards justice and accountability, potentially undermining claims of fairness and equality.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Qwen/Qwen3-1.7B\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Useful\",\n          \"Unhelpful\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tiiuae/Falcon3-1B-Instruct\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Useful\",\n          \"Unhelpful\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"majority_vote\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"Useful\",\n          \"**Validated Critical Question:**\\n\\n**How does Trump's decision to settle a lawsuit without admitting guilt impact his stance on discrimination issues?**\\n\\nThis question effectively challenges the statement about discrimination by exploring the implications of not admitting guilt in legal disputes. It prompts consideration of how such decisions might reflect broader attitudes towards justice and accountability, potentially undermining claims of fairness and equality.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}","type":"dataframe"},"text/html":["\n","  <div id=\"df-b5cf87b9-8e6e-4e52-b856-90593453ea17\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>intervention_id</th>\n","      <th>cq_id</th>\n","      <th>intervention</th>\n","      <th>cq</th>\n","      <th>ground_truth</th>\n","      <th>Qwen/Qwen2.5-1.5B-Instruct</th>\n","      <th>Qwen/Qwen3-1.7B</th>\n","      <th>tiiuae/Falcon3-1B-Instruct</th>\n","      <th>majority_vote</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>17th_knight__247</td>\n","      <td>17th_knight__247_LLM_us2016reddit_D_meta-llama...</td>\n","      <td>17th: \"They should get the coverage\\nThey are ...</td>\n","      <td>What is the author's definition of \"they are a...</td>\n","      <td>Useful</td>\n","      <td>Useful</td>\n","      <td>Unhelpful</td>\n","      <td>Unhelpful</td>\n","      <td>Unhelpful</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Antanagoge_104</td>\n","      <td>Antanagoge_104_LLM_rrd_D_meta-llama_Meta-Llama...</td>\n","      <td>Antanagoge: \"The airline industry can not be l...</td>\n","      <td>How significant are the psychological effects ...</td>\n","      <td>Useful</td>\n","      <td>Useful</td>\n","      <td>Unhelpful</td>\n","      <td>Useful</td>\n","      <td>Useful</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Bill_106</td>\n","      <td>Bill_106_LLM_rrd_D_meta-llama_Meta-Llama-3-70B...</td>\n","      <td>Bill: \"I run a retail business.\\nIf I changed ...</td>\n","      <td>Has Bill explored alternative explanations for...</td>\n","      <td>Useful</td>\n","      <td>Unhelpful</td>\n","      <td>Unhelpful</td>\n","      <td>Useful</td>\n","      <td>Unhelpful</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>CLINTON_103</td>\n","      <td>CLINTON_103_T__1</td>\n","      <td>CLINTON: \"I think you 've seen another example...</td>\n","      <td>If so, can the practical inconsistency between...</td>\n","      <td>Unhelpful</td>\n","      <td>Unhelpful</td>\n","      <td>Unhelpful</td>\n","      <td>Useful</td>\n","      <td>Unhelpful</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>CLINTON_103</td>\n","      <td>CLINTON_103_T__3</td>\n","      <td>CLINTON: \"I think you 've seen another example...</td>\n","      <td>Is it possible for the particular case of Trum...</td>\n","      <td>Unhelpful</td>\n","      <td>Unhelpful</td>\n","      <td>Unhelpful</td>\n","      <td>Unhelpful</td>\n","      <td>Unhelpful</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>95</th>\n","      <td>smg_72</td>\n","      <td>smg_72_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-I...</td>\n","      <td>smg: \"It has become abundantly clear that comm...</td>\n","      <td>How would these regulations \"level the playing...</td>\n","      <td>Useful</td>\n","      <td>Unhelpful</td>\n","      <td>Unhelpful</td>\n","      <td>Useful</td>\n","      <td>Unhelpful</td>\n","    </tr>\n","    <tr>\n","      <th>96</th>\n","      <td>smg_72</td>\n","      <td>smg_72_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-I...</td>\n","      <td>smg: \"It has become abundantly clear that comm...</td>\n","      <td>How would these regulations affect the airline...</td>\n","      <td>Useful</td>\n","      <td>Unhelpful</td>\n","      <td>Unhelpful</td>\n","      <td>Unhelpful</td>\n","      <td>Unhelpful</td>\n","    </tr>\n","    <tr>\n","      <th>97</th>\n","      <td>smg_72</td>\n","      <td>smg_72_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-I...</td>\n","      <td>smg: \"It has become abundantly clear that comm...</td>\n","      <td>Are there any alternative solutions to the pro...</td>\n","      <td>Unhelpful</td>\n","      <td>Unhelpful</td>\n","      <td>Unhelpful</td>\n","      <td>Unhelpful</td>\n","      <td>Unhelpful</td>\n","    </tr>\n","    <tr>\n","      <th>98</th>\n","      <td>travellots_133_1</td>\n","      <td>travellots_133_1_LLM_rrd_D_meta-llama_Meta-Lla...</td>\n","      <td>travellots: \"There should be no discrimination...</td>\n","      <td>Are there any differences between purchasing a...</td>\n","      <td>Useful</td>\n","      <td>Useful</td>\n","      <td>Unhelpful</td>\n","      <td>Useful</td>\n","      <td>Useful</td>\n","    </tr>\n","    <tr>\n","      <th>99</th>\n","      <td>travellots_133_2</td>\n","      <td>travellots_133_2_LLM_rrd_D_meta-llama_Meta-Lla...</td>\n","      <td>travellots: \"If compensation is not high enoug...</td>\n","      <td>Is the comparison between bumping passengers a...</td>\n","      <td>Unhelpful</td>\n","      <td>Useful</td>\n","      <td>Unhelpful</td>\n","      <td>Unhelpful</td>\n","      <td>Unhelpful</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>100 rows × 9 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b5cf87b9-8e6e-4e52-b856-90593453ea17')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-b5cf87b9-8e6e-4e52-b856-90593453ea17 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-b5cf87b9-8e6e-4e52-b856-90593453ea17');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-cec8fbb6-f554-4575-8f34-4b5153fdf03c\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cec8fbb6-f554-4575-8f34-4b5153fdf03c')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-cec8fbb6-f554-4575-8f34-4b5153fdf03c button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"text/plain":["     intervention_id                                              cq_id  \\\n","0   17th_knight__247  17th_knight__247_LLM_us2016reddit_D_meta-llama...   \n","1     Antanagoge_104  Antanagoge_104_LLM_rrd_D_meta-llama_Meta-Llama...   \n","2           Bill_106  Bill_106_LLM_rrd_D_meta-llama_Meta-Llama-3-70B...   \n","3        CLINTON_103                                   CLINTON_103_T__1   \n","4        CLINTON_103                                   CLINTON_103_T__3   \n","..               ...                                                ...   \n","95            smg_72  smg_72_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-I...   \n","96            smg_72  smg_72_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-I...   \n","97            smg_72  smg_72_LLM_rrd_D_meta-llama_Meta-Llama-3-70B-I...   \n","98  travellots_133_1  travellots_133_1_LLM_rrd_D_meta-llama_Meta-Lla...   \n","99  travellots_133_2  travellots_133_2_LLM_rrd_D_meta-llama_Meta-Lla...   \n","\n","                                         intervention  \\\n","0   17th: \"They should get the coverage\\nThey are ...   \n","1   Antanagoge: \"The airline industry can not be l...   \n","2   Bill: \"I run a retail business.\\nIf I changed ...   \n","3   CLINTON: \"I think you 've seen another example...   \n","4   CLINTON: \"I think you 've seen another example...   \n","..                                                ...   \n","95  smg: \"It has become abundantly clear that comm...   \n","96  smg: \"It has become abundantly clear that comm...   \n","97  smg: \"It has become abundantly clear that comm...   \n","98  travellots: \"There should be no discrimination...   \n","99  travellots: \"If compensation is not high enoug...   \n","\n","                                                   cq ground_truth  \\\n","0   What is the author's definition of \"they are a...       Useful   \n","1   How significant are the psychological effects ...       Useful   \n","2   Has Bill explored alternative explanations for...       Useful   \n","3   If so, can the practical inconsistency between...    Unhelpful   \n","4   Is it possible for the particular case of Trum...    Unhelpful   \n","..                                                ...          ...   \n","95  How would these regulations \"level the playing...       Useful   \n","96  How would these regulations affect the airline...       Useful   \n","97  Are there any alternative solutions to the pro...    Unhelpful   \n","98  Are there any differences between purchasing a...       Useful   \n","99  Is the comparison between bumping passengers a...    Unhelpful   \n","\n","   Qwen/Qwen2.5-1.5B-Instruct Qwen/Qwen3-1.7B tiiuae/Falcon3-1B-Instruct  \\\n","0                      Useful       Unhelpful                  Unhelpful   \n","1                      Useful       Unhelpful                     Useful   \n","2                   Unhelpful       Unhelpful                     Useful   \n","3                   Unhelpful       Unhelpful                     Useful   \n","4                   Unhelpful       Unhelpful                  Unhelpful   \n","..                        ...             ...                        ...   \n","95                  Unhelpful       Unhelpful                     Useful   \n","96                  Unhelpful       Unhelpful                  Unhelpful   \n","97                  Unhelpful       Unhelpful                  Unhelpful   \n","98                     Useful       Unhelpful                     Useful   \n","99                     Useful       Unhelpful                  Unhelpful   \n","\n","   majority_vote  \n","0      Unhelpful  \n","1         Useful  \n","2      Unhelpful  \n","3      Unhelpful  \n","4      Unhelpful  \n","..           ...  \n","95     Unhelpful  \n","96     Unhelpful  \n","97     Unhelpful  \n","98        Useful  \n","99     Unhelpful  \n","\n","[100 rows x 9 columns]"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["add_majority_vote(\"/content/results_wide.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t3880Bp_XtUe"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyO9cmSTYMwkEHirbV4/zKLH"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"32c95c86449e4e1c82dc2d30dedb61ef":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"34897a436809423dafba66220c6011b3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_62b9acf536264e18b11b7a4bb9c6d365","placeholder":"​","style":"IPY_MODEL_a73329c051d94808a019345d1eab2838","value":"Loading checkpoint shards: 100%"}},"48b8d5946c9a4c4f830ab03bc3537c8d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e30e5873acc64ca3837825291aa0c38d","placeholder":"​","style":"IPY_MODEL_32c95c86449e4e1c82dc2d30dedb61ef","value":" 2/2 [00:01&lt;00:00,  1.53it/s]"}},"62b9acf536264e18b11b7a4bb9c6d365":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"995308d1825e486a823dccddad9852a7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a73329c051d94808a019345d1eab2838":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d5c768ab157e4d6eb2b735c326e065af":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e30e5873acc64ca3837825291aa0c38d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f02032a4f43a4dabab90107a96c16a14":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_34897a436809423dafba66220c6011b3","IPY_MODEL_ff6a5ba9105c4102a44922acfc8c068c","IPY_MODEL_48b8d5946c9a4c4f830ab03bc3537c8d"],"layout":"IPY_MODEL_d5c768ab157e4d6eb2b735c326e065af"}},"fb1abc5f506148a6a32658a752378e76":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ff6a5ba9105c4102a44922acfc8c068c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_995308d1825e486a823dccddad9852a7","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fb1abc5f506148a6a32658a752378e76","value":2}}}}},"nbformat":4,"nbformat_minor":0}